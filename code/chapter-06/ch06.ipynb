{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ch06.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "VCFoUNxQN5-6",
        "yPgnpgvURYGU",
        "sNfGcloXRu8J"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VCFoUNxQN5-6"
      },
      "source": [
        "## TensorFlow ProfilerとTensorBoard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yt62PUwdOmbN",
        "outputId": "7d5e6c2f-a399-4bb6-8c5e-f75dba6423e6"
      },
      "source": [
        "pip install -U tensorboard-plugin-profile"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorboard-plugin-profile in /usr/local/lib/python3.7/dist-packages (2.5.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard-plugin-profile) (1.0.1)\n",
            "Requirement already satisfied: gviz-api>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard-plugin-profile) (1.10.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard-plugin-profile) (1.15.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard-plugin-profile) (3.17.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard-plugin-profile) (57.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YxyXedriN2s7",
        "outputId": "b01b4603-fa73-4086-fb2c-f3d9903f4b85"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "\n",
        "x_train = x_train/255.\n",
        "x_test = x_test/255.\n",
        "\n",
        "model = tf.keras.models.Sequential((\n",
        "    tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
        "    tf.keras.layers.MaxPool2D(2),\n",
        "    tf.keras.layers.Conv2D(64, 3, activation='relu'),\n",
        "    tf.keras.layers.MaxPool2D(2),\n",
        "    tf.keras.layers.Conv2D(128, 3, activation='relu'),\n",
        "    tf.keras.layers.MaxPool2D(2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "))\n",
        "\n",
        "model.compile(\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    optimizer='adam'\n",
        ")\n",
        "\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=\"logs\", profile_batch=7)\n",
        "\n",
        "model.fit(x_train, y_train, epochs=2, callbacks=[tensorboard_callback])"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "1563/1563 [==============================] - 14s 8ms/step - loss: 1.5854\n",
            "Epoch 2/2\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 1.2173\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f5e50461a50>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DhEaA6xsPmCl"
      },
      "source": [
        "ローカルで実行している場合は、 `tensorboard` コマンドを実行してください。Google Colaboratory を利用している場合は、以下のコードで TensorBoeard を起動し、ノートブック内に表示できます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Z6RItwobN47s",
        "outputId": "a58f67a6-d7d2-4cb3-9075-4d398a4c2f40"
      },
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir logs"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Reusing TensorBoard on port 6006 (pid 157), started 1:03:39 ago. (Use '!kill 157' to kill it.)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        (async () => {\n",
              "            const url = new URL(await google.colab.kernel.proxyPort(6006, {'cache': true}));\n",
              "            url.searchParams.set('tensorboardColab', 'true');\n",
              "            const iframe = document.createElement('iframe');\n",
              "            iframe.src = url;\n",
              "            iframe.setAttribute('width', '100%');\n",
              "            iframe.setAttribute('height', '800');\n",
              "            iframe.setAttribute('frameborder', 0);\n",
              "            document.body.appendChild(iframe);\n",
              "        })();\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xy8GqPWqPU4F"
      },
      "source": [
        "## データの準備\n",
        "\n",
        "以下のコードは原著の[サンプルコード](https://github.com/PracticalDL/Practical-Deep-Learning-Book/blob/master/code/chapter-6/storing-data-as-tfrecord.ipynb)を日本語版に合わせて修正したものです。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LxP8ie8ZQcB2",
        "outputId": "310b118d-6355-4338-d06e-2b3f4d722eb9"
      },
      "source": [
        "# 画像ファイルをダウンロード\n",
        "!curl https://raw.githubusercontent.com/PracticalDL/Practical-Deep-Learning-Book/master/sample-images/cat.jpg --output cat.jpg"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100  661k  100  661k    0     0  2689k      0 --:--:-- --:--:-- --:--:-- 2689k\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PG3tNecvPcme"
      },
      "source": [
        "import tensorflow as tf\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import io\n",
        "\n",
        "cat = \"cat.jpg\"\n",
        "img_name_to_labels = {cat: 0}\n",
        "img_in_string = open(cat, 'rb').read()\n",
        "label_for_img = img_name_to_labels[cat]\n",
        "\n",
        "# 下記の関数を使うと値を tf.Example と互換性の有る型に変換できる\n",
        "\n",
        "def _bytes_feature(value):\n",
        "  \"\"\"string / byte 型から byte_list を返す\"\"\"\n",
        "  if isinstance(value, type(tf.constant(0))):\n",
        "    value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n",
        "  return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
        "\n",
        "def _float_feature(value):\n",
        "  \"\"\"float / double 型から float_list を返す\"\"\"\n",
        "  return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
        "\n",
        "def _int64_feature(value):\n",
        "  \"\"\"bool / enum / int / uint 型から Int64_list を返す\"\"\"\n",
        "  return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
        "\n",
        "\n",
        "def get_tfrecord(img, label):\n",
        " feature = {\n",
        "    'label': _int64_feature(label),\n",
        "    'image_raw': _bytes_feature(img),\n",
        " }\n",
        " return tf.train.Example(features=tf.train.Features(feature=feature))\n",
        "\n",
        "with tf.io.TFRecordWriter('img.tfrecord') as writer:\n",
        "  for filename, label in img_name_to_labels.items():\n",
        "    image_string = open(filename, 'rb').read()\n",
        "    tf_example = get_tfrecord(image_string, label)\n",
        "    writer.write(tf_example.SerializeToString())"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZezbULapQ9m7",
        "outputId": "14654909-412e-4936-9226-f275382eb1e6"
      },
      "source": [
        "# img.tfrecord が生成されていることを確認\n",
        "!ls"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cat.jpg  img.tfrecord  logs  sample_data  tmp.h5  training_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7X4ZNTo4RE2v",
        "outputId": "70549a18-f9e5-4f57-f56c-18a901f18a88"
      },
      "source": [
        "# TFRecordファイルの読み込み\n",
        "\n",
        "dataset = tf.data.TFRecordDataset('img.tfrecord')\n",
        "ground_truth_info = {\n",
        "  'label': tf.compat.v1.FixedLenFeature([], tf.int64),\n",
        "  'image_raw': tf.compat.v1.FixedLenFeature([], tf.string),\n",
        "}\n",
        "\n",
        "def map_operation(read_data):\n",
        "  return tf.compat.v1.parse_single_example(read_data, ground_truth_info)\n",
        "\n",
        "imgs = dataset.map(map_operation)\n",
        "\n",
        "for image_features in imgs:\n",
        "  image_raw = image_features['image_raw'].numpy()\n",
        "  label = image_features['label'].numpy()\n",
        "  image = Image.open(io.BytesIO(image_raw))\n",
        "  image.show()\n",
        "  print(label)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yPgnpgvURYGU"
      },
      "source": [
        "## TensorFlow Datasetsを利用する"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BUQUcqrvRQiv",
        "outputId": "cc4fe796-4476-48e9-9d2b-757bd0ad98ff"
      },
      "source": [
        "import tensorflow_datasets as tfds\n",
        "\n",
        "# 利用可能なデータセットを表示します\n",
        "print(tfds.list_builders())"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['abstract_reasoning', 'accentdb', 'aeslc', 'aflw2k3d', 'ag_news_subset', 'ai2_arc', 'ai2_arc_with_ir', 'amazon_us_reviews', 'anli', 'arc', 'bair_robot_pushing_small', 'bccd', 'beans', 'big_patent', 'bigearthnet', 'billsum', 'binarized_mnist', 'binary_alpha_digits', 'blimp', 'bool_q', 'c4', 'caltech101', 'caltech_birds2010', 'caltech_birds2011', 'cars196', 'cassava', 'cats_vs_dogs', 'celeb_a', 'celeb_a_hq', 'cfq', 'chexpert', 'cifar10', 'cifar100', 'cifar10_1', 'cifar10_corrupted', 'citrus_leaves', 'cityscapes', 'civil_comments', 'clevr', 'clic', 'clinc_oos', 'cmaterdb', 'cnn_dailymail', 'coco', 'coco_captions', 'coil100', 'colorectal_histology', 'colorectal_histology_large', 'common_voice', 'coqa', 'cos_e', 'cosmos_qa', 'covid19sum', 'crema_d', 'curated_breast_imaging_ddsm', 'cycle_gan', 'deep_weeds', 'definite_pronoun_resolution', 'dementiabank', 'diabetic_retinopathy_detection', 'div2k', 'dmlab', 'downsampled_imagenet', 'dsprites', 'dtd', 'duke_ultrasound', 'emnist', 'eraser_multi_rc', 'esnli', 'eurosat', 'fashion_mnist', 'flic', 'flores', 'food101', 'forest_fires', 'fuss', 'gap', 'geirhos_conflict_stimuli', 'genomics_ood', 'german_credit_numeric', 'gigaword', 'glue', 'goemotions', 'gpt3', 'groove', 'gtzan', 'gtzan_music_speech', 'hellaswag', 'higgs', 'horses_or_humans', 'i_naturalist2017', 'imagenet2012', 'imagenet2012_corrupted', 'imagenet2012_real', 'imagenet2012_subset', 'imagenet_a', 'imagenet_r', 'imagenet_resized', 'imagenet_v2', 'imagenette', 'imagewang', 'imdb_reviews', 'irc_disentanglement', 'iris', 'kitti', 'kmnist', 'lfw', 'librispeech', 'librispeech_lm', 'libritts', 'ljspeech', 'lm1b', 'lost_and_found', 'lsun', 'malaria', 'math_dataset', 'mctaco', 'mnist', 'mnist_corrupted', 'movie_lens', 'movie_rationales', 'movielens', 'moving_mnist', 'multi_news', 'multi_nli', 'multi_nli_mismatch', 'natural_questions', 'natural_questions_open', 'newsroom', 'nsynth', 'nyu_depth_v2', 'omniglot', 'open_images_challenge2019_detection', 'open_images_v4', 'openbookqa', 'opinion_abstracts', 'opinosis', 'opus', 'oxford_flowers102', 'oxford_iiit_pet', 'para_crawl', 'patch_camelyon', 'paws_wiki', 'paws_x_wiki', 'pet_finder', 'pg19', 'places365_small', 'plant_leaves', 'plant_village', 'plantae_k', 'qa4mre', 'qasc', 'quickdraw_bitmap', 'radon', 'reddit', 'reddit_disentanglement', 'reddit_tifu', 'resisc45', 'robonet', 'rock_paper_scissors', 'rock_you', 'salient_span_wikipedia', 'samsum', 'savee', 'scan', 'scene_parse150', 'scicite', 'scientific_papers', 'sentiment140', 'shapes3d', 'smallnorb', 'snli', 'so2sat', 'speech_commands', 'spoken_digit', 'squad', 'stanford_dogs', 'stanford_online_products', 'starcraft_video', 'stl10', 'sun397', 'super_glue', 'svhn_cropped', 'ted_hrlr_translate', 'ted_multi_translate', 'tedlium', 'tf_flowers', 'the300w_lp', 'tiny_shakespeare', 'titanic', 'trec', 'trivia_qa', 'tydi_qa', 'uc_merced', 'ucf101', 'vctk', 'vgg_face2', 'visual_domain_decathlon', 'voc', 'voxceleb', 'voxforge', 'waymo_open_dataset', 'web_questions', 'wider_face', 'wiki40b', 'wikihow', 'wikipedia', 'wikipedia_toxicity_subtypes', 'wine_quality', 'winogrande', 'wmt14_translate', 'wmt15_translate', 'wmt16_translate', 'wmt17_translate', 'wmt18_translate', 'wmt19_translate', 'wmt_t2t_translate', 'wmt_translate', 'wordnet', 'xnli', 'xquad', 'xsum', 'yelp_polarity_reviews', 'yes_no']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7cBkBgxaRhGR"
      },
      "source": [
        "train_dataset = tfds.load(name=\"cifar100\", split=tfds.Split.TRAIN)\n",
        "train_dataset = train_dataset.shuffle(2048).batch(64)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sNfGcloXRu8J"
      },
      "source": [
        "## tf.data を利用する\n",
        "\n",
        "以下のコードを実行するには、`training_data` ディレクトリ以下に訓練データセットが保存されている必要があります。ここでは、 **TensorFlow Datasetsを利用する** でダウンロードした cifar100 データセットを用います"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQmVi33RTNWW"
      },
      "source": [
        "# ダウンロードした cifar100 データセットから tfrecord をコピーする\n",
        "!mkdir -p training_data\n",
        "!cp ~/tensorflow_datasets/cifar100/*/cifar100-train.tfrecord* training_data/cifar100-train.tfrecord"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UZKLXnD5yB1R"
      },
      "source": [
        "features = {\n",
        "    'image': tf.io.FixedLenFeature([], tf.string),\n",
        "    'label': tf.io.FixedLenFeature([], tf.int64)\n",
        "}\n",
        "\n",
        "def preprocess(example):\n",
        "    data = tf.io.parse_single_example(example, features=features)\n",
        "    image = data['image']\n",
        "    label = data['label']\n",
        "\n",
        "    # image は正規化する\n",
        "    image = tf.cast(image, tf.float32)\n",
        "    image /= 255.\n",
        "\n",
        "    return image, label"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JUgGGCwRzk3_"
      },
      "source": [
        "files = tf.data.Dataset.list_files(\"./training_data/*.tfrecord\")\n",
        "dataset = tf.data.TFRecordDataset(files)\n",
        "\n",
        "dataset = dataset.shuffle(2048) \\\n",
        "                 .repeat() \\\n",
        "                 .map(preprocess) \\\n",
        "                 .batch(64)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83EkhUi1Rt4k"
      },
      "source": [
        "options = tf.data.Options()\n",
        "options.experimental_deterministic = False\n",
        "# options.experimental_optimization.filter_fusion = True\n",
        "# options.experimental_optimization.map_and_filter_fusion = True\n",
        "# options.experimental_optimization.map_fusion = True\n",
        "\n",
        "dataset = tf.data.Dataset.list_files(\"./training_data/*.tfrecord\")\n",
        "dataset = dataset.with_options(options)\n",
        "dataset = files.interleave(tf.data.TFRecordDataset,\n",
        "                            num_parallel_calls=tf.data.AUTOTUNE)\n",
        "dataset = dataset.map(preprocess,\n",
        "                            num_parallel_calls=tf.data.AUTOTUNE)\n",
        "dataset = dataset.cache() \n",
        "dataset = dataset.repeat() \n",
        "dataset = dataset.shuffle(2048)\n",
        "dataset = dataset.batch(batch_size=64) \n",
        "dataset = dataset.prefetch(buffer_size=tf.data.AUTOTUNE)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DKcS0sXZ29hv"
      },
      "source": [
        "## 最適な学習率を見つける"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2rU3SHdA3mKu",
        "outputId": "f2115e55-1db5-4a72-e805-c84aa03860a8"
      },
      "source": [
        "pip install keras_lr_finder"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras_lr_finder in /usr/local/lib/python3.7/dist-packages (0.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from keras_lr_finder) (3.2.2)\n",
            "Requirement already satisfied: keras>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from keras_lr_finder) (2.7.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->keras_lr_finder) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->keras_lr_finder) (2.8.2)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib->keras_lr_finder) (1.19.5)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->keras_lr_finder) (3.0.6)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->keras_lr_finder) (1.3.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->keras_lr_finder) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453
        },
        "id": "ls2HnemD2-Sl",
        "outputId": "02d2324a-fd4d-4734-8fef-1b40125079f3"
      },
      "source": [
        "from keras_lr_finder import LRFinder\n",
        "\n",
        "lr_finder = LRFinder(model)\n",
        "lr_finder.find(x_train, y_train, start_lr=0.0001, end_lr=10, batch_size=512,\n",
        "               epochs=5)\n",
        "lr_finder.plot_loss(n_skip_beginning=20, n_skip_end=5)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "98/98 [==============================] - 4s 34ms/step - loss: 1.0300\n",
            "Epoch 2/5\n",
            "98/98 [==============================] - 3s 30ms/step - loss: 0.9985\n",
            "Epoch 3/5\n",
            "98/98 [==============================] - 3s 30ms/step - loss: 1.8998\n",
            "Epoch 4/5\n",
            "98/98 [==============================] - 3s 30ms/step - loss: 2.3069\n",
            "Epoch 5/5\n",
            "98/98 [==============================] - 3s 30ms/step - loss: 2.3819\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PFsINziJ4A0H"
      },
      "source": [
        "## tf.functionを利用する"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZMzADU0O3v4C",
        "outputId": "2db081ad-97db-4e61-b15d-7d5682dae5ef"
      },
      "source": [
        "import timeit\n",
        "\n",
        "\n",
        "conv_layer = tf.keras.layers.Conv2D(224, 3)\n",
        "\n",
        "def non_tf_func(image):\n",
        "  for _ in range(1,3):\n",
        "        conv_layer(image)\n",
        "  return\n",
        "\n",
        "@tf.function\n",
        "def tf_func(image):\n",
        "  for _ in range(1,3):\n",
        "        conv_layer(image)\n",
        "  return\n",
        "\n",
        "mat = tf.zeros([1, 100, 100, 100])\n",
        "\n",
        "# ウォームアップ\n",
        "non_tf_func(mat)\n",
        "tf_func(mat)\n",
        "\n",
        "print(\"Without @tf.function:\", timeit.timeit(lambda: non_tf_func(mat),\n",
        "      number=10000), \" seconds\")\n",
        "print(\"With @tf.function:\", timeit.timeit(lambda: tf_func(mat), number=10000),\n",
        "      \"seconds\")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Without @tf.function: 62.75666024800012  seconds\n",
            "With @tf.function: 4.026196660000096 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WwwHp1f44Eof"
      },
      "source": [
        ""
      ],
      "execution_count": 16,
      "outputs": []
    }
  ]
}