{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table class=\"tfo-notebook-buttons\" align=\"center\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/practicaldl/Practical-Deep-Learning-Book/blob/master/code/chapter-4/4-improving-accuracy-with-fine-tuning.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://github.com/practicaldl/Practical-Deep-Learning-Book/blob/master/code/chapter-4/4-improving-accuracy-with-fine-tuning.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
    "  </td>\n",
    "</table>\n",
    "\n",
    "This code is part of [Chapter 4 - Building a Reverse Image Search Engine: Understanding Embeddings](https://learning.oreilly.com/library/view/practical-deep-learning/9781492034858/ch04.html).\n",
    "\n",
    "Note: In order to run this notebook on Google Colab you need to [follow these instructions](https://colab.research.google.com/github/googlecolab/colabtools/blob/master/notebooks/colab-github-demo.ipynb#scrollTo=WzIRIt9d2huC) so that the local data such as the images are available in your Google Drive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improving accuracy with Fine-Tuning\n",
    "\n",
    "\n",
    "Many of the pre-trained models were trained on the ImageNet dataset. Therefore, they provide an incredible starting point for similarity computations in most situations. That said, if you tune these models to adapt to your specific problem, they would perform even more accurately for finding similar images. \n",
    "\n",
    "In this portion of the chapter, we will find the least accurate (worst) performing categories, visualize them with t-SNE, fine-tune and then see how their t-SNE graph changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "import random\n",
    "import time\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "import PIL\n",
    "from PIL import Image\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import random\n",
    "from textwrap import wrap\n",
    "\n",
    "import glob\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We utilize the helper functions we used before in previous notebooks here as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to get the classname\n",
    "def classname(str):\n",
    "    return str.split('/')[-2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper function to display accuracy stats and plot similar images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display(dic, per_class, neighbors, message):\n",
    "    for key in dic:\n",
    "        print(key, \"\\tAccuracy: \", per_class[key])\n",
    "    for each_class in dic:\n",
    "        indices_of_class = [\n",
    "            i for i, j in enumerate(filenames) if classname(j) == each_class\n",
    "        ]\n",
    "        random_image_index = random.choice(indices_of_class)\n",
    "        distances, indices = neighbors.kneighbors(\n",
    "            [feature_list[random_image_index]])\n",
    "        similar_image_paths = [filenames[random_image_index]] + \\\n",
    "            [filenames[indices[0][i]] for i in range(1, 4)]\n",
    "        plot_images(similar_image_paths, distances[0], message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper function that calculates accuracy using the Nearest Neighbours Brute force algorithm and returns the classes that the model performed least accurately on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_least_accurate_classes(feature_list):\n",
    "    per_class_acc = {}\n",
    "    num_nearest_neighbors = 5\n",
    "    num_correct_predictions = 0\n",
    "    num_incorrect_predictions = 0\n",
    "    neighbors = NearestNeighbors(n_neighbors=num_nearest_neighbors,\n",
    "                                 algorithm='brute',\n",
    "                                 metric='euclidean').fit(feature_list)\n",
    "    for i in tqdm_notebook(range(len(feature_list))):\n",
    "        distances, indices = neighbors.kneighbors([feature_list[i]])\n",
    "        for j in range(1, num_nearest_neighbors):\n",
    "            predicted_class = classname(filenames[indices[0][j]])\n",
    "            ground_truth = classname(filenames[i])\n",
    "            if (predicted_class not in per_class_acc):\n",
    "                per_class_acc[predicted_class] = [0, 0, 0]\n",
    "            if ground_truth == predicted_class:\n",
    "                num_correct_predictions += 1\n",
    "                per_class_acc[predicted_class][0] += 1\n",
    "                per_class_acc[predicted_class][2] += 1\n",
    "            else:\n",
    "                num_incorrect_predictions += 1\n",
    "                per_class_acc[predicted_class][1] += 1\n",
    "                per_class_acc[predicted_class][2] += 1\n",
    "    print(\n",
    "        \"Accuracy is \",\n",
    "        round(\n",
    "            100.0 * num_correct_predictions /\n",
    "            (1.0 * num_correct_predictions + num_incorrect_predictions), 2))\n",
    "    for key, value in per_class_acc.items():\n",
    "        per_class_acc[key] = round(100.0 * value[0] / (1.0 * value[2]), 2)\n",
    "    dic = sorted(per_class_acc, key=per_class_acc.get)\n",
    "\n",
    "    # least_accurate classes\n",
    "    print(\"\\n\\nTop 10 incorrect classifications\\n\")\n",
    "    for key in dic[:10]:\n",
    "        print(key, \"\\tAccuracy: \", per_class_acc[key])\n",
    "    return dic[:6], per_class_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the features of the Caltech256 dataset to run our experiments on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset features\n",
    "filenames = pickle.load(open('data/filenames-caltech256.pickle', 'rb'))\n",
    "feature_list = pickle.load(open('data/features-caltech256-resnet.pickle', 'rb'))\n",
    "class_ids = pickle.load(open('data/class_ids-caltech256.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the PCA model on the loaded features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform PCA over the features\n",
    "# set the number of features intended\n",
    "num_feature_dimensions = 100\n",
    "pca = PCA(n_components=num_feature_dimensions)\n",
    "pca.fit(feature_list)\n",
    "feature_list = pca.transform(feature_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Note: We are using the classes with the least accuracy because the effect of finetuning is expected be most pronounced on these categories. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_of_least_accurate_classes_before_finetuning, accuracy_per_class_before_finetuning = get_least_accurate_classes(\n",
    "    feature_list[:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print names of the least accurate classes before fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_of_least_accurate_classes_before_finetuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine the features from the 6 least accurate classes into a list so that we can use this list for further experiments and visualization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "least_accurate_feature_list = []\n",
    "least_accurate_filenames = []\n",
    "least_accurate_count = {}\n",
    "for index, filename in enumerate(filenames):\n",
    "    if classname(filename) not in least_accurate_count:\n",
    "        least_accurate_count[classname(filename)] = 0\n",
    "    if classname(\n",
    "            filename\n",
    "    ) in names_of_least_accurate_classes_before_finetuning and least_accurate_count[\n",
    "            classname(filename)] <= 50:\n",
    "        least_accurate_feature_list.append(feature_list[index])\n",
    "        least_accurate_count[classname(filename)] += 1\n",
    "        least_accurate_filenames.append(class_ids[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train t-SNE only on the 6 least accurate classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "selected_features = least_accurate_feature_list\n",
    "selected_class_ids = least_accurate_filenames\n",
    "selected_filenames = least_accurate_filenames\n",
    "time_start = time.time()\n",
    "tsne_results = TSNE(n_components=2, verbose=1,\n",
    "                    metric='euclidean').fit_transform(selected_features)\n",
    "# tsne = TSNE(n_components=2, verbose=1, perplexity=40, n_iter=250, metric=’euclidean’)\n",
    "print('t-SNE done! Time elapsed: {} seconds'.format(time.time() - time_start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### t-SNE visualization of feature vectors of least accurate classes before finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.title(\"\\n\".join(\n",
    "    wrap(\n",
    "        \"t-SNE visualization of feature vectors of least accurate classes before finetuning\",\n",
    "        60)))\n",
    "set_classes = list(set(selected_class_ids))\n",
    "# set different markers for all the classes we are going to show\n",
    "markers = [\"^\", \".\", \"s\", \"o\", \"x\", \"P\"]\n",
    "# set different colors for all the classes we are going to show\n",
    "colors = ['red', 'blue', 'fuchsia', 'green', 'purple', 'orange']\n",
    "class_to_marker = {}\n",
    "class_to_color = {}\n",
    "for index in range(len(tsne_results)):\n",
    "    # assign color and marker to each type of class\n",
    "    if selected_class_ids[index] not in class_to_marker:\n",
    "        class_to_marker[selected_class_ids[index]] = markers.pop()\n",
    "    if selected_class_ids[index] not in class_to_color:\n",
    "        class_to_color[selected_class_ids[index]] = colors.pop()\n",
    "    plt.scatter(tsne_results[index, 0],\n",
    "                tsne_results[index, 1],\n",
    "                c=class_to_color[selected_class_ids[index]],\n",
    "                marker=class_to_marker[selected_class_ids[index]],\n",
    "                edgecolor='white',\n",
    "                linewidth='.6',\n",
    "                s=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These feature vectors are all over the place! Using these feature vectors in other applications such as classification might not be a good idea as it would be difficult to find a plane of separation between them. \n",
    "\n",
    "\n",
    "Read the finetuned features from the Caltech-256 dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = pickle.load(open('data/filenames-caltech256.pickle', 'rb'))\n",
    "feature_list = pickle.load(\n",
    "    open('data/features-caltech256-resnet-finetuned.pickle', 'rb'))\n",
    "class_ids = pickle.load(open('data/class_ids-caltech256.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform PCA over the features\n",
    "# set the number of features intended\n",
    "num_feature_dimensions = 100\n",
    "pca = PCA(n_components=num_feature_dimensions)\n",
    "pca.fit(feature_list)\n",
    "feature_list = pca.transform(feature_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine the features from the 6 least accurate classes into a list so that we can use this list for further experiments and visualization. Note that we are using the same categories (`names_of_least_accurate_classes_before_finetuning`) as before to enable an apples-to-apples comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "least_accurate_feature_list = []\n",
    "least_accurate_filenames = []\n",
    "least_accurate_count = {}\n",
    "for index, filename in enumerate(filenames):\n",
    "    if classname(filename) not in least_accurate_count:\n",
    "        least_accurate_count[classname(filename)] = 0\n",
    "    if classname(\n",
    "            filename\n",
    "    ) in names_of_least_accurate_classes_before_finetuning and least_accurate_count[\n",
    "            classname(filename)] <= 50:\n",
    "        least_accurate_feature_list.append(feature_list[index])\n",
    "        least_accurate_count[classname(filename)] += 1\n",
    "        least_accurate_filenames.append(class_ids[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a t-SNE model using the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "selected_features = least_accurate_feature_list\n",
    "selected_class_ids = least_accurate_filenames\n",
    "selected_filenames = least_accurate_filenames\n",
    "time_start = time.time()\n",
    "tsne_results = TSNE(n_components=2, verbose=1,\n",
    "                    metric='euclidean').fit_transform(selected_features)\n",
    "# tsne = TSNE(n_components=2, verbose=1, perplexity=40, n_iter=250, metric=’euclidean’)\n",
    "print('t-SNE done! Time elapsed: {} seconds'.format(time.time() - time_start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### t-SNE visualization of feature vectors of least accurate classes after finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.title(\"\\n\".join(\n",
    "    wrap(\n",
    "        \"t-SNE visualization of feature vectors of least accurate classes after finetuning\",\n",
    "        60)))\n",
    "plt.tight_layout()\n",
    "set_classes = list(set(selected_class_ids))\n",
    "markers = [\"^\", \".\", \"s\", \"o\", \"x\", \"P\"]\n",
    "colors = ['red', 'blue', 'fuchsia', 'green', 'purple', 'orange']\n",
    "class_to_marker = {}\n",
    "class_to_color = {}\n",
    "for index in range(len(tsne_results)):\n",
    "    # get only those tsne_results which belong to each_class\n",
    "    if selected_class_ids[index] not in class_to_marker:\n",
    "        class_to_marker[selected_class_ids[index]] = markers.pop()\n",
    "    if selected_class_ids[index] not in class_to_color:\n",
    "        class_to_color[selected_class_ids[index]] = colors.pop()\n",
    "    scatterPlot = plt.scatter(\n",
    "        tsne_results[index, 0],\n",
    "        tsne_results[index, 1],\n",
    "        c=class_to_color[selected_class_ids[index]],\n",
    "        marker=class_to_marker[selected_class_ids[index]],\n",
    "        edgecolor='white',\n",
    "        linewidth='.6',\n",
    "        s=80)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is so much cleaner. With just a little bit of fine tuning as shown in chapter 2, the embeddings start to group together. Compare the noisy/scattered embeddings of the pre-trained models against those of the fine-tuned model. A machine learning classifier would be able to find a plane of separation between these classes with much more ease, hence giving better classification accuracy as well as more similar images when not using a classifier. And, remember, these were the classes with the highest misclassifications, imagine how nicely the classes with originally higher accuracy would be after fine-tuning.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
